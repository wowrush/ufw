# dflare_sys.py
"""
D-FLARE SYS â€” å¤šå±¤é›†æˆå¼é˜²ç«ç‰†å¨è„…åˆ†ç´šç³»çµ±ï¼ˆCisco ASA 5506-X å°ˆç”¨ï¼‰
æ”¯æ´æµæ°´è™Ÿï¼ˆbatch_idï¼‰èˆ‡ append æ©Ÿåˆ¶
"""

import os
import sys
import csv
import json
import time
import pandas as pd
from tqdm import tqdm
from colorama import init, Fore, Style

init(autoreset=True)

# ==== å–å¾—æ–°çš„ batch_idï¼ˆå¾ all_results.csv æª”æ¡ˆè‡ªå‹•éå¢ï¼‰====
def get_next_batch_id(all_results_path):
    if not os.path.exists(all_results_path):
        return 1
    try:
        df = pd.read_csv(all_results_path)
        if "batch_id" in df.columns and not df.empty:
            return int(df["batch_id"].max()) + 1
        else:
            return 1
    except Exception:
        return 1

# =============== STEP1ï¼šè³‡æ–™æ¸…æ´— + å”¯ä¸€å€¼ ===============
def step1_process_logs(raw_log_path, step1_out_path, unique_out_json, batch_id, show_progress=True):
    STANDARD_COLUMNS = [
        "batch_id", "Datetime", "SyslogID", "Severity", "SourceIP", "SourcePort",
        "DestinationIP", "DestinationPort", "Duration", "Bytes",
        "Protocol", "Action", "Description", "raw_log"
    ]
    unique_vals = {col: set() for col in STANDARD_COLUMNS}
    CHUNK_SIZE = 50000

    def detect_encoding(file_path):
        import chardet
        with open(file_path, 'rb') as f:
            return chardet.detect(f.read(10000)).get('encoding', 'utf-8') or 'utf-8'

    print(f"{Fore.CYAN}{Style.BRIGHT}STEP1ï¼šé–‹å§‹è³‡æ–™æ¸…æ´—èˆ‡å”¯ä¸€å€¼çµ±è¨ˆ")
    encoding = detect_encoding(raw_log_path)
    total_lines = sum(1 for _ in open(raw_log_path, encoding=encoding))
    processed_count = 0

    with open(raw_log_path, "r", encoding=encoding, errors="replace") as f, \
         open(step1_out_path, "w", newline='', encoding="utf-8") as out_f:
        reader = csv.DictReader(f)
        writer = csv.DictWriter(out_f, fieldnames=STANDARD_COLUMNS)
        writer.writeheader()
        pbar = tqdm(reader, total=total_lines-1, desc=f"{Fore.CYAN}æ¸…æ´—é€²åº¦", disable=not show_progress)
        for i, row in enumerate(pbar):
            record = {col: row.get(col, "") for col in STANDARD_COLUMNS if col != "batch_id" and col != "raw_log"}
            record["batch_id"] = batch_id
            record["raw_log"] = json.dumps(row, ensure_ascii=False)
            # è£œé½Šç©ºæ¬„
            for col in STANDARD_COLUMNS:
                if col not in record:
                    record[col] = "unknown"
                unique_vals[col].add(record[col])
            writer.writerow(record)
            processed_count += 1
            if (i+1) % 10000 == 0:
                pbar.set_postfix_str(f"{Fore.YELLOW}å·²è™•ç† {i+1} ç­†ï¼Œå”¯ä¸€å€¼ç´¯è¨ˆï¼š{ {k: len(v) for k, v in unique_vals.items()} }")
            if (i+1) % CHUNK_SIZE == 0:
                out_f.flush()
        print(f"{Fore.GREEN}{Style.BRIGHT}STEP1 çµæŸï¼Œå…±è™•ç† {processed_count} ç­†è³‡æ–™ã€‚")

    unique_json = {k: sorted(list(v)) for k, v in unique_vals.items()}
    with open(unique_out_json, "w", encoding="utf-8") as f:
        json.dump(unique_json, f, ensure_ascii=False, indent=4)
    print(f"{Fore.GREEN}{Style.BRIGHT}STEP1 å®Œæˆï¼šå·²è¼¸å‡º {step1_out_path} åŠ {unique_out_json}")
# =============== STEP2ï¼šè³‡æ–™é è™•ç† ===============
def step2_preprocess_data(step1_out_path, step2_out_path, unique_json, show_progress=True):
    with open(unique_json, "r", encoding="utf-8") as f:
        unique_vals = json.load(f)
    CATEGORICAL_MAPPINGS = {
        "Protocol": {
            "http": 1, "https": 2, "icmp": 3, "tcp": 4, "udp": 5,
            "scan": 6, "flood": 7, "other": 8, "unknown": 0, "nan": -1
        },
        "Action": {
            "built": 1, "teardown": 2, "deny": 3, "drop": 4,
            "login": 5, "other": 6, "unknown": 0, "nan": -1
        }
    }
    print(f"{Fore.CYAN}{Style.BRIGHT}STEP2ï¼šé–‹å§‹æ¬„ä½æ¨™æº–åŒ–èˆ‡æ˜ å°„")
    CHUNK_SIZE = 50000
    column_order = [
        "batch_id", "Datetime", "SyslogID", "Severity", "is_attack", "SourceIP", "SourcePort",
        "DestinationIP", "DestinationPort", "Duration", "Bytes", "Protocol",
        "Action", "Description", "raw_log"
    ]
    chunks = []
    total = sum(1 for _ in open(step1_out_path, encoding="utf-8"))
    processed = 0
    numeric_cols = ["SourcePort", "DestinationPort", "Duration", "Bytes"]

    def is_attack_severity(x):
        try:
            return 1 if int(str(x).strip()) <= 4 else 0
        except Exception:
            return 0

    for chunk in tqdm(pd.read_csv(step1_out_path, chunksize=CHUNK_SIZE), desc=f"{Fore.CYAN}é è™•ç†é€²åº¦", disable=not show_progress, total=total//CHUNK_SIZE+1):
        # æ¬„ä½æ˜ å°„/å‹æ…‹è£œé½Š
        for col, mapping in CATEGORICAL_MAPPINGS.items():
            if col in chunk.columns:
                chunk[col] = chunk[col].astype(str).str.lower().map(mapping).fillna(-1).astype(int)
        # is_attackï¼ˆä¿®æ­£ï¼šç”¨ int+strip é˜²å‘†ï¼‰
        if "Severity" in chunk.columns:
            chunk["is_attack"] = chunk["Severity"].apply(is_attack_severity)
        else:
            chunk["is_attack"] = 0

        # æ•¸å€¼æ¬„ä½
        for col in numeric_cols:
            if col in chunk.columns:
                chunk[col] = pd.to_numeric(chunk[col], errors="coerce").fillna(0).astype(int)
        # æ¬„ä½é †åºèˆ‡è£œç¼º
        for col in column_order:
            if col not in chunk.columns:
                chunk[col] = ""
        chunk = chunk[column_order]
        chunks.append(chunk)
        processed += len(chunk)
        tqdm.write(f"{Fore.YELLOW}STEP2 ç´¯è¨ˆé è™•ç†ï¼š{processed} ç­†")
    df = pd.concat(chunks, ignore_index=True)
    before = len(df)
    df.drop_duplicates(inplace=True)
    after = len(df)
    print(f"{Fore.GREEN}å»é™¤é‡è¤‡è³‡æ–™ {before-after} ç­†ï¼Œå…±ä¿ç•™ {after} ç­†")
    df.to_csv(step2_out_path, index=False, encoding="utf-8")
    print(f"{Fore.GREEN}{Style.BRIGHT}STEP2 å®Œæˆï¼šå·²è¼¸å‡º {step2_out_path}")
# ========== STEP3-1ï¼šäºŒå…ƒæ¨¡å‹é æ¸¬+åœ–è¡¨ ==========
def dflare_binary_predict(input_csv, binary_model_path, output_csv, output_pie, output_bar, feat_cols=None, show_progress=True):
    import matplotlib.pyplot as plt
    from matplotlib.font_manager import FontProperties
    import joblib
    from matplotlib.ticker import MaxNLocator
    import os

    if os.name == "nt":
        font_path = "C:/Windows/Fonts/msjh.ttc"
    elif os.path.exists("/System/Library/Fonts/PingFang.ttc"):
        font_path = "/System/Library/Fonts/PingFang.ttc"
    else:
        font_path = "/usr/share/fonts/truetype/arphic/uming.ttc"
    font_name = FontProperties(fname=font_path).get_name()
    plt.rcParams['font.family'] = font_name
    plt.rcParams['axes.unicode_minus'] = False
    plt.rcParams['figure.facecolor'] = "#fcfcfc"
    pie_colors = ["#ff9800", "#888888"]

    tqdm.write(f"{Fore.CYAN}{Style.BRIGHT}STEP3-1ï¼šè¼‰å…¥é è™•ç†è³‡æ–™èˆ‡äºŒå…ƒæ¨¡å‹...")
    df = pd.read_csv(input_csv, encoding="utf-8")
    bin_model = joblib.load(binary_model_path)

    # ç‰¹å¾µæ¬„ä½è‡ªå‹•å°é½Šï¼ˆåªå–æ¨¡å‹è¨“ç·´éçš„æ¬„ä½ï¼Œbatch_idè‡ªå‹•æ’é™¤ï¼‰

    if hasattr(bin_model, "feature_names_in_"):
        model_feat_cols = list(bin_model.feature_names_in_)
    elif feat_cols is not None:
        model_feat_cols = feat_cols
    else:
        raise RuntimeError("äºŒå…ƒæ¨¡å‹æœªå­˜ç‰¹å¾µåç¨±ï¼Œè«‹æ˜ç¢ºæŒ‡å®š feat_colsã€‚")
    # åªä¿ç•™æ¨¡å‹éœ€è¦çš„æ¬„ä½ï¼Œä¸å¤šä¸å°‘ï¼Œä¸æœƒæœ‰ batch_id
    df_model = df.reindex(columns=model_feat_cols, fill_value=-1)
    df_model = df_model.fillna(-1).astype(int)

    tqdm.write(f"{Fore.CYAN}{Style.BRIGHT}STEP3-1ï¼šäºŒå…ƒæ¨¡å‹é æ¸¬èˆ‡åœ–è¡¨ç”¢ç”Ÿä¸­...")
    df['is_attack'] = bin_model.predict(df_model)
    df.to_csv(output_csv, index=False, encoding="utf-8")
    tqdm.write(f"{Fore.GREEN}{Style.BRIGHT}STEP3-1ï¼šäºŒå…ƒåˆ¤æ–·å·²è¼¸å‡º {output_csv}")

    # ç¹ªåœ–ï¼šis_attack åˆ†å¸ƒ
    is_attack_dist = df['is_attack'].value_counts().sort_index().reindex([0, 1], fill_value=0)
    labels_attack = ['æ­£å¸¸æµé‡', 'æ”»æ“Šæµé‡']
    pie_base_colors = ["#04ff11", "#FF0000"]  # æ­£å¸¸ã€æ”»æ“Š

    # åœ“é¤…åœ–
    
    nonzero_idx = [i for i, v in enumerate(is_attack_dist) if v > 0]
    pie_values = [is_attack_dist.iloc[i] for i in nonzero_idx]
    pie_labels = [labels_attack[i] for i in nonzero_idx]
    pie_colors = [pie_base_colors[i] for i in nonzero_idx]
    plt.figure(figsize=(6, 6))
    if len(pie_values) == 0:
        plt.text(0.5, 0.5, 'ç„¡è³‡æ–™', fontsize=20, ha='center', va='center')
        plt.axis('off')
    elif len(pie_values) == 1:
        plt.pie(
            [1], labels=[pie_labels[0]], colors=[pie_colors[0]],
            autopct='lambda', textprops={'fontsize': 16},
            startangle=90, wedgeprops={'edgecolor': 'white', 'linewidth': 2}
        )
    else:
        plt.pie(
            pie_values, labels=pie_labels,
            autopct=lambda pct: ('%1.1f%%' % pct) if pct > 0 else '',
            colors=pie_colors, textprops={'fontsize': 16},
            startangle=90, wedgeprops={'edgecolor': 'white', 'linewidth': 2}
        )
    plt.title("æ”»æ“Šèˆ‡æ­£å¸¸æµé‡æ¯”ä¾‹ï¼ˆäºŒå…ƒï¼‰", fontsize=18, pad=20)
    plt.tight_layout()
    plt.savefig(output_pie, bbox_inches='tight')
    plt.close()

    # é•·æ¢åœ–
    plt.figure(figsize=(7, 5))
    ax = plt.gca()
    ax.yaxis.set_major_locator(MaxNLocator(integer=True))
    plt.bar(labels_attack, is_attack_dist, color=pie_base_colors, edgecolor="#333", width=0.6)
    plt.xlabel('æµé‡é¡å‹', fontsize=15, labelpad=10)
    plt.ylabel('æ•¸é‡', fontsize=15, labelpad=10)
    plt.title('æ”»æ“Šèˆ‡æ­£å¸¸æµé‡æ•¸é‡åˆ†å¸ƒï¼ˆäºŒå…ƒï¼‰', fontsize=18, pad=20)
    for idx, v in enumerate(is_attack_dist):
        plt.text(idx, v + 0.05, str(v), ha='center', va='bottom', fontsize=15)
    plt.tight_layout()
    plt.savefig(output_bar, bbox_inches='tight')
    plt.close()

    return {
        "output_csv": output_csv,
        "output_pie": output_pie,
        "output_bar": output_bar,
        "is_attack_distribution": is_attack_dist.to_dict(),
        "count_all": int(df.shape[0]),
        "count_attack": int(is_attack_dist[1]),
        "count_normal": int(is_attack_dist[0]),
    }, df

# ========== STEP3-2ï¼šå¤šå…ƒæ¨¡å‹é æ¸¬+åœ–è¡¨ ==========
def dflare_multiclass_predict(df_attack, multiclass_model_path, output_csv, output_pie, output_bar, feat_cols=None, show_progress=True):
    import matplotlib.pyplot as plt
    from matplotlib.font_manager import FontProperties
    import joblib
    from matplotlib.ticker import MaxNLocator
    import os

    if os.name == "nt":
        font_path = "C:/Windows/Fonts/msjh.ttc"
    elif os.path.exists("/System/Library/Fonts/PingFang.ttc"):
        font_path = "/System/Library/Fonts/PingFang.ttc"
    else:
        font_path = "/usr/share/fonts/truetype/arphic/uming.ttc"
    font_name = FontProperties(fname=font_path).get_name()
    plt.rcParams['font.family'] = font_name
    plt.rcParams['axes.unicode_minus'] = False
    plt.rcParams['figure.facecolor'] = "#fcfcfc"

    severity_map = {1: 'å±éšª', 2: 'é«˜', 3: 'ä¸­', 4: 'ä½'}
    show_levels = [1, 2, 3, 4]
    sev_labels = [severity_map[i] for i in show_levels]
    colors_sev = ["#d32f2f", "#f57c08", "#fbc02d", "#04ff11"]

    tqdm.write(f"{Fore.CYAN}{Style.BRIGHT}STEP3-2ï¼šè¼‰å…¥æ”»æ“Šæµé‡èˆ‡å¤šå…ƒæ¨¡å‹...")

    mul_model = joblib.load(multiclass_model_path)
    if hasattr(mul_model, "feature_names_in_"):
        model_feat_cols = list(mul_model.feature_names_in_)
    elif feat_cols is not None:
        model_feat_cols = feat_cols
    else:
        raise RuntimeError("å¤šå…ƒæ¨¡å‹æœªå­˜ç‰¹å¾µåç¨±ï¼Œè«‹æ˜ç¢ºæŒ‡å®š feat_colsã€‚")
    df_model = df_attack.reindex(columns=model_feat_cols, fill_value=-1)
    df_model = df_model.fillna(-1).astype(int)

    tqdm.write(f"{Fore.CYAN}{Style.BRIGHT}STEP3-2ï¼šå¤šå…ƒæ¨¡å‹åˆ†ç´šèˆ‡åœ–è¡¨ç”¢ç”Ÿä¸­...")
    df_attack['Severity'] = mul_model.predict(df_model)
    df_attack.to_csv(output_csv, index=False, encoding="utf-8")
    tqdm.write(f"{Fore.GREEN}{Style.BRIGHT}STEP3-2ï¼šå¤šå…ƒåˆ†ç´šå·²è¼¸å‡º {output_csv}")

    # åªé‡å°æ”»æ“Šæµé‡ Severity åˆ†å¸ƒ
    sev_dist = df_attack['Severity'].value_counts().sort_index().reindex(show_levels, fill_value=0)
    sev_labels = [severity_map[i] for i in show_levels]
    colors_sev = ["#d32f2f", "#f57c08", "#fbc02d", "#04ff11"]
    
    # åœ“é¤…åœ–
    nonzero_idx = [i for i, v in enumerate(sev_dist) if v > 0]
    pie_values = [sev_dist.iloc[i] for i in nonzero_idx]
    pie_labels = [sev_labels[i] for i in nonzero_idx]
    pie_colors = [colors_sev[i] for i in nonzero_idx]
    plt.figure(figsize=(6, 6))
    if len(pie_values) == 0:
        plt.text(0.5, 0.5, 'ç„¡æ”»æ“Šæµé‡', fontsize=20, ha='center', va='center')
        plt.axis('off')
    elif len(pie_values) == 1:
        plt.pie(
            [1], labels=[pie_labels[0]], colors=[pie_colors[0]],
            autopct='lambda', textprops={'fontsize': 16},
            startangle=90, wedgeprops={'edgecolor': 'white', 'linewidth': 2}
        )
    else:
        plt.pie(
            pie_values, labels=pie_labels,
            autopct=lambda pct: ('%1.1f%%' % pct) if pct > 0 else '',
            colors=pie_colors, textprops={'fontsize': 16},
            startangle=90, wedgeprops={'edgecolor': 'white', 'linewidth': 2}
        )
    plt.title("Severity åˆ†å¸ƒï¼ˆåƒ…é‡å°æ”»æ“Šæµé‡ï¼‰", fontsize=18, pad=20)
    plt.tight_layout()
    plt.savefig(output_pie, bbox_inches='tight')
    plt.close()

    # é•·æ¢åœ–ï¼ˆæ‰€æœ‰æ¨™ç±¤å…¨å‡ºç¾ï¼Œ0 ä¹Ÿè¦ç•«å‡º barï¼‰
    plt.figure(figsize=(7, 5))
    ax = plt.gca()
    ax.yaxis.set_major_locator(MaxNLocator(integer=True))
    plt.bar(sev_labels, sev_dist, color=colors_sev, edgecolor="#333", width=0.6)
    plt.xlabel('Severity ç­‰ç´šï¼ˆ4ç‚ºæœ€ä½ï¼Œ1ç‚ºæœ€é«˜ï¼‰', fontsize=15, labelpad=10)
    plt.ylabel('æ•¸é‡', fontsize=15, labelpad=10)
    plt.title('Severity åˆ†å¸ƒï¼ˆåƒ…é‡å°æ”»æ“Šæµé‡ï¼‰', fontsize=18, pad=20)
    for idx, v in enumerate(sev_dist):
        plt.text(idx, v + 0.05, str(v), ha='center', va='bottom', fontsize=15)
    plt.tight_layout()
    plt.savefig(output_bar, bbox_inches='tight')
    plt.close()
    return {
        "output_csv": output_csv,
        "output_pie": output_pie,
        "output_bar": output_bar,
        "severity_distribution": sev_dist.to_dict(),
        "count_all": int(df_attack.shape[0]),
        "message": "å¤šå…ƒåˆ†ç´šçµæœå·²ç”¢ç”Ÿ"
    }

# ========== PIPELINE ==========
def dflare_sys_full_pipeline(
    raw_log_path, binary_model_path, multiclass_model_path, output_dir,
    all_results_csv="all_results.csv",
    bin_feat_cols=None, multi_feat_cols=None, show_progress=True
):
    os.makedirs(output_dir, exist_ok=True)

    # ====== [1] æ‰¹æ¬¡æµæ°´è™Ÿå–å¾—ï¼ˆæ¯ä¸€æ‰¹å”¯ä¸€ï¼‰ ======
    all_results_path = os.path.join(output_dir, all_results_csv)
    batch_id = get_next_batch_id(all_results_path)

    # ====== [2] æ¯æ‰¹æš«å­˜æª”æ¡ˆï¼ˆè¦†è“‹å³å¯ï¼Œä¸åšæ­·å²ä¿ç•™ï¼‰ ======
    step1_out = os.path.join(output_dir, "processed_logs.csv")
    unique_json = os.path.join(output_dir, "log_unique_values.json")
    step2_out = os.path.join(output_dir, "preprocessed_data.csv")
    binary_csv = os.path.join(output_dir, "binary_result.csv")
    binary_pie = os.path.join(output_dir, "binary_pie.png")
    binary_bar = os.path.join(output_dir, "binary_bar.png")
    multi_csv = os.path.join(output_dir, "multiclass_result.csv")
    multi_pie = os.path.join(output_dir, "multiclass_pie.png")
    multi_bar = os.path.join(output_dir, "multiclass_bar.png")

    # ====== [3] ETL Pipeline ======
    step1_process_logs(raw_log_path, step1_out, unique_json, batch_id, show_progress)
    step2_preprocess_data(step1_out, step2_out, unique_json, show_progress)

    # ====== [4] äºŒå…ƒæ¨¡å‹ï¼ˆå…¨è³‡æ–™é æ¸¬ï¼‰ ======
    bin_res, df_bin = dflare_binary_predict(
        input_csv=step2_out,
        binary_model_path=binary_model_path,
        output_csv=binary_csv,
        output_pie=binary_pie,
        output_bar=binary_bar,
        feat_cols=bin_feat_cols,
        show_progress=show_progress
    )

    # ====== [5] å¤šå…ƒæ¨¡å‹ï¼ˆåƒ…æ”»æ“Šæµé‡é æ¸¬ï¼‰ ======
    df_bin["is_attack"] = pd.to_numeric(df_bin["is_attack"], errors="coerce").fillna(0).astype(int)
    df_attack = df_bin[df_bin['is_attack'] == 1].copy()
    if df_attack.empty:
        print(f"{Fore.YELLOW}{Style.BRIGHT}æœ¬æ‰¹è³‡æ–™ç„¡æ”»æ“Šæµé‡ï¼ˆis_attack=1ï¼‰ï¼Œè·³éå¤šå…ƒåˆ†ç´šã€‚")
        # ç›´æ¥ append åˆ° all_results.csv
        write_header = not os.path.exists(all_results_path)
        df_bin["batch_id"] = batch_id
        with open(all_results_path, "a", newline='', encoding="utf-8") as allf:
            df_bin.to_csv(allf, header=write_header, index=False)
        return {
            "batch_id": batch_id,
            "binary": bin_res,
            "multiclass": None,
            "binary_output_csv": binary_csv,
            "binary_output_pie": binary_pie,
            "binary_output_bar": binary_bar,
            "multiclass_output_csv": None,
            "multiclass_output_pie": None,
            "multiclass_output_bar": None,
            "all_results_csv": all_results_path,
            "message": "æœ¬æ‰¹ç„¡æ”»æ“Šæµé‡ï¼Œå·²è·³éå¤šå…ƒåˆ†ç´š"
        }

    # æœ‰æ”»æ“Šæµé‡æ‰é€²è¡Œå¤šå…ƒåˆ†ç´š
    multi_res = dflare_multiclass_predict(
        df_attack=df_attack,
        multiclass_model_path=multiclass_model_path,
        output_csv=multi_csv,
        output_pie=multi_pie,
        output_bar=multi_bar,
        feat_cols=multi_feat_cols,
        show_progress=show_progress
    )

    # ====== [6] APPEND æœ¬æ‰¹çµæœåˆ° all_results.csvï¼ˆåƒ…è¿½åŠ ï¼Œä¸è¦†è“‹ï¼‰======
    write_header = not os.path.exists(all_results_path)
    df_bin["batch_id"] = batch_id
    with open(all_results_path, "a", newline='', encoding="utf-8") as allf:
        df_bin.to_csv(allf, header=write_header, index=False)

    # ====== [7] å›å‚³æ‰€æœ‰ output è·¯å¾‘ï¼Œæš«å­˜åƒ…ä¿ç•™æœ€æ–°ï¼Œall_results ç´¯ç©è¿½è¹¤ ======
    return {
        "batch_id": batch_id,
        "binary": bin_res,
        "multiclass": multi_res,
        "binary_output_csv": binary_csv,
        "binary_output_pie": binary_pie,
        "binary_output_bar": binary_bar,
        "multiclass_output_csv": multi_csv,
        "multiclass_output_pie": multi_pie,
        "multiclass_output_bar": multi_bar,
        "all_results_csv": all_results_path,
    }

# ==================== CLI/GUI å…±ç”¨ä¸»å…¥å£ ====================
if __name__ == "__main__":
    import argparse
    import tkinter as tk
    from tkinter import filedialog
    from tkinter import messagebox
    import os

    parser = argparse.ArgumentParser(
        description="D-FLARE SYS å…¨æµç¨‹è‡ªå‹•æ‰¹æ¬¡å·¥å…·ï¼ˆCisco ASA 5506-Xï¼‰"
    )
    parser.add_argument('--raw_log', type=str, help='åŸå§‹ log æª”è·¯å¾‘ï¼ˆcsv/txt/gzï¼‰')
    parser.add_argument('--bin_model', type=str, help='äºŒå…ƒæ¨¡å‹ .pkl è·¯å¾‘')
    parser.add_argument('--multi_model', type=str, help='å¤šå…ƒæ¨¡å‹ .pkl è·¯å¾‘')
    parser.add_argument('--output_dir', type=str, help='æ‰€æœ‰è¼¸å‡ºæª”å­˜æ”¾è³‡æ–™å¤¾')
    parser.add_argument('--no_progress', action="store_true", help='ä¸é¡¯ç¤ºé€²åº¦æ¢')
    args = parser.parse_args()

    # ç”¨ tkinter é¸æª” (äº’å‹•)
    def pick_file(title="è«‹é¸æ“‡æª”æ¡ˆ", filetypes=[("æ‰€æœ‰æª”æ¡ˆ", "*.*")]):
        root = tk.Tk()
        root.withdraw()
        file_path = filedialog.askopenfilename(title=title, filetypes=filetypes)
        root.destroy()
        return file_path

    def pick_folder(title="è«‹é¸æ“‡è³‡æ–™å¤¾"):
        root = tk.Tk()
        root.withdraw()
        folder_path = filedialog.askdirectory(title=title)
        root.destroy()
        return folder_path

    # æª¢æŸ¥åƒæ•¸ï¼Œè‹¥æ²’æŒ‡å®šå°±äº’å‹•é¸æ“‡
    raw_log = args.raw_log or pick_file("è«‹é¸æ“‡åŸå§‹ log æª”", [("CSV", "*.csv"), ("æ–‡å­—", "*.txt"), ("GZ", "*.gz"), ("æ‰€æœ‰æª”æ¡ˆ", "*.*")])
    bin_model = args.bin_model or pick_file("è«‹é¸æ“‡äºŒå…ƒæ¨¡å‹ .pkl æª”", [("Pickle", "*.pkl")])
    multi_model = args.multi_model or pick_file("è«‹é¸æ“‡å¤šå…ƒæ¨¡å‹ .pkl æª”", [("Pickle", "*.pkl")])
    output_dir = args.output_dir or pick_folder("è«‹é¸æ“‡è¼¸å‡ºè³‡æ–™å¤¾")
    show_progress = not args.no_progress

    print(f"{Fore.CYAN}{Style.BRIGHT}ğŸš¦ å•Ÿå‹• D-FLARE SYS å…¨æµç¨‹ Pipelineï¼ˆäºŒå…ƒ+å¤šå…ƒï¼Œæ”¯æ´ batch_id èˆ‡ appendï¼‰...")
    t0 = time.time()
    result = dflare_sys_full_pipeline(
        raw_log_path=raw_log,
        binary_model_path=bin_model,
        multiclass_model_path=multi_model,
        output_dir=output_dir,
        bin_feat_cols=None,
        multi_feat_cols=None,
        show_progress=show_progress
    )
    print(f"{Fore.GREEN}{Style.BRIGHT}ğŸš€ å…¨æµç¨‹å®Œæˆï¼çµæœå·²è¼¸å‡ºè‡³ï¼š{output_dir}")
    print(json.dumps(result, ensure_ascii=False, indent=2))
    print(f"{Fore.CYAN}{Style.BRIGHT}ç¸½è€—æ™‚ï¼š{time.time() - t0:.1f} ç§’ã€‚")
